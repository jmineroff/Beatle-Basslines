{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BassGeneration.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/jmineroff/Beatle-Basslines/blob/master/BassGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"OBXDJWvwLQvw","colab_type":"code","colab":{}},"source":["# Optional code cell for running in Google Colab\n","# Links to local git folder in Google Drive and installs modules\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install pypianoroll\n","!pip install AudioConverter\n","!apt install fluidsynth\n","!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n","!pip install midi2audio\n","\n","import os\n","try:\n","  os.chdir(\"drive/My Drive/Beatle-Basslines\") # Local git path\n","except Exception:\n","  pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyykK17l1wod","colab_type":"code","colab":{}},"source":["# Initialization\n","\n","from midi2audio import FluidSynth as fs\n","from IPython.display import display, Audio\n","import numpy as np\n","import pandas as pd\n","from pypianoroll import Multitrack, Track\n","from matplotlib import pyplot as plt\n","import os\n","import sys\n","\n","plt.rcParams[\"figure.figsize\"] = (20,10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRXvxj0k06Rd","colab_type":"code","colab":{}},"source":["# Helper functions\n","\n","def write_soundfile(midifile, output): # Write midi to an audio file\n","  fs(sound_font=\"font.sf2\", sample_rate=11025).midi_to_audio(midifile, output)\n","\n","\n","def piano_plot(pianofile): # \n","  fig, axs = pianofile.plot()\n","  plt.show()\n","\n","\n","def parse_midi_dir(list_songs=True, list_tracks=False): # Parse directory of raw midi files\n","  num_midi = 0\n","\n","  for subdir, dirs, files in os.walk('RawMIDI/'):\n","    for file in files:\n","      num_midi += 1\n","      \n","      if not file.endswith(\".mid\"):\n","        continue\n","        \n","      if list_songs:\n","        print(subdir.split('/')[-1],'-',file)\n","      \n","      if list_tracks:\n","        filepath = subdir + os.sep + file\n","        temp = Multitrack(filepath)\n","        for track in temp.tracks: # \n","          print('...',track.name)\n","\n","  print('Track count:',num_midi)\n","\n","def tempo_to_progress(tempo): # Get song progress (0-1) from beat-uniform tempo array\n","  return np.cumsum(1/tempo) / np.sum(1/tempo)\n","\n","\n","def add_songs_to_df(df, partial_track_match=False, binarize=False): # Add all songs to dataframe\n","  note_limits = {'Drums': [127,0], 'Bass': [127,0], 'Vocals': [127,0], 'Rhythm': [127,0], 'Lead': [127,0]}\n","  note_counts = {'Drums': 0, 'Bass': 0, 'Vocals': 0, 'Rhythm': 0, 'Lead': 0}\n","      \n","  for subdir, dirs, files in os.walk('RawMIDI/'): # Walk through all files in directory\n","    for file in files:\n","      \n","      track_to_channel = {'Drums': [], 'Bass': [], 'Vocals': [], 'Rhythm': [], 'Lead': [], 'VocalsAll': []}\n","      \n","      if not file.endswith(\".mid\"): # Only process MIDI files\n","        continue\n","\n","      print('Processing', subdir.split('/')[-1], '-', file) # Status update\n","\n","      filepath = subdir + os.sep + file\n","      temp = Multitrack(filepath)\n","\n","      for track_idx, track in enumerate(temp.tracks): # Parse all tracks in midi file\n","        for key in track_to_channel: # Compare all keys to track name\n","          if ( track.name == key ) or ( partial_track_match and track.name.startswith(key) ): # Exact or partial track-key match (depending on 'partial_track_match')\n","            track_to_channel[key].append(track_idx)\n","\n","      if not track_to_channel['Vocals']: # Copy index from 'VocalsAll' to 'Vocals' if necessary\n","        track_to_channel['Vocals'] = track_to_channel['VocalsAll']\n","      \n","      del track_to_channel['VocalsAll']\n","\n","      for key in track_to_channel: # Set index of nonexistent tracks to -1\n","        if not track_to_channel[key]:\n","          track_to_channel[key].append(-1)\n","      \n","      if binarize:\n","        temp.binarize()\n","\n","      full_pianoroll = temp.get_stacked_pianoroll()\n","      full_pianoroll = np.append(full_pianoroll, np.zeros((*full_pianoroll.shape[0:2],1)), axis=2) # Add extra track of zeros for nonexistent tracks\n","\n","      tempo = temp.tempo\n","      downbeat = temp.downbeat\n","\n","      progress = tempo_to_progress(tempo)\n","\n","      pianorolls = {}\n","\n","      # Get instrument pianorolls from full pianoroll using dictionary indices\n","      for key in track_to_channel: # \n","        \n","        if binarize:\n","          pianorolls[key] = np.amax(full_pianoroll[:,:,track_to_channel[key]], axis=2)\n","        else:\n","          pianorolls[key] = np.sum(full_pianoroll[:,:,track_to_channel[key]], axis=2)\n","\n","        note_locations = np.flatnonzero(np.amax(pianorolls[key], axis=0))\n","        note_count = np.amax(np.count_nonzero(pianorolls[key], axis=1))\n","\n","        #print(len(note_locations))\n","        #print(note_locations)\n","        #print(note_count)\n","        \n","        if not note_locations.any():\n","          continue\n","\n","        high_note = np.amin(note_locations)\n","        low_note = np.amax(note_locations)\n","        if high_note < note_limits[key][0]:\n","          note_limits[key][0] = high_note\n","        if low_note > note_limits[key][1]:\n","          note_limits[key][1] = low_note\n","        if note_count > note_counts[key]:\n","          note_counts[key] = note_count\n","      \n","      # Add new entry to dataframe\n","      df.loc[len(df)] = [file.split('.')[0], subdir.split('/')[-1], pianorolls['Drums'], pianorolls['Bass'], pianorolls['Vocals'], pianorolls['Rhythm'], pianorolls['Lead'], tempo, downbeat, progress]\n","\n","  return note_limits, note_counts\n","\n","\n","def manual_song_test(df, song_name): # Generate original and recombined audio for manual comparison\n","  # Build track from original MIDI file\n","  filepath = 'RawMIDI/' + df.loc[df.Song == song_name].Album.values[0] + '/' + song_name + '.mid'\n","\n","  original = Multitrack(filepath)\n","  #piano_plot(original)\n","\n","  original.write('temp/original.mid')\n","  write_soundfile('temp/original.mid', 'temp/original.mp3')\n","  print('Original File')\n","  display(Audio('temp/original.mp3'))\n","  \n","  # Build track from dataframe\n","  drum_track = Track(df.loc[df.Song == song_name].Drums.values[0], is_drum=True, name='Drums')\n","  bass_track = Track(df.loc[df.Song == song_name].Bass.values[0], program=34, is_drum=False, name='Bass')\n","  vocal_track = Track(df.loc[df.Song == song_name].Vocals.values[0], program=73, is_drum=False, name='Vocals')\n","  rhythm_track = Track(df.loc[df.Song == song_name].Rhythm.values[0], program=24, is_drum=False, name='Rhythm')\n","  lead_track = Track(df.loc[df.Song == song_name].Lead.values[0], program=26, is_drum=False, name='Lead')\n","  tempo = df.loc[df.Song == song_name].Tempo.values[0]\n","  downbeat = df.loc[df.Song == song_name].Downbeat.values[0]\n","\n","  bass_track.transpose(-12) # Only intermittently needed for proper playback with FluidSynth Soundfont - don't use for exporting raw MIDI files\n","  \n","  recombined = Multitrack(tracks=[drum_track, bass_track, vocal_track, rhythm_track, lead_track], tempo=tempo, downbeat=downbeat)\n","\n","  recombined.write('temp/recombined.mid')\n","  write_soundfile('temp/recombined.mid', 'temp/recombined.mp3')\n","  print('Recombined File')\n","  display(Audio('temp/recombined.mp3'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"24Vo4OjJlnBW","colab_type":"code","colab":{}},"source":["# Write all song/track names to a text file\n","from contextlib import redirect_stdout\n","\n","with open('TrackList.txt', 'w') as f:\n","  with redirect_stdout(f):\n","    parse_midi_dir(list_tracks=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmBfSst7YkRl","colab_type":"code","colab":{}},"source":["# Initialize dataframe\n","col_names = ['Song','Album','Drums','Bass','Vocals','Rhythm','Lead','Tempo','Downbeat','Progress']\n","raw_songs_df = pd.DataFrame(columns = col_names)\n","raw_songs_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WkvfmZ2Zi8K","colab_type":"code","colab":{}},"source":["# Populate dataframe\n","note_limits, note_counts = add_songs_to_df(raw_songs_df, partial_track_match=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMbV14_5Fm9t","colab_type":"code","colab":{}},"source":["# Check df\n","print('Note limits:', note_limits)\n","print('Note counts:', note_counts)\n","raw_songs_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l33xvSiZTkA9","colab_type":"code","colab":{}},"source":["# Compare original MIDI audio with recombined df audio\n","manual_song_test(raw_songs_df, 'Rain')"],"execution_count":0,"outputs":[]}]}